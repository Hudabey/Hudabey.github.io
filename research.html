<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Research - Hudeifa Hassan</title>
  <meta name="description" content="Hudeifa Hassan's research projects">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

  <!-- Navigation -->
  <nav>
    <div class="container">
      <a href="index.html" class="nav-brand">hudeifa hassan</a>
      <button class="mobile-toggle" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Toggle menu">
        &#9776;
      </button>
      <ul class="nav-links">
        <li><a href="index.html">home</a></li>
        <li><a href="research.html" class="active">research</a></li>
        <li><a href="blog.html">blog</a></li>
        <li><a href="#">cv</a></li>
      </ul>
    </div>
  </nav>

  <main class="container">

    <section class="hero" style="margin-bottom: 48px;">
      <h1>Research</h1>
      <p class="tagline">Current and past research projects</p>
    </section>

    <!-- Current Research -->
    <section>
      <h2 class="section-header">Current</h2>
      <div class="research-list">

        <div class="research-item">
          <div class="research-item-header">
            <h3>Sparse Attention Patterns in Video Diffusion: Do They Preserve Semantic Consistency Across Frames?</h3>
            <span class="status-badge active">&#9679; in progress</span>
          </div>
          <p>
            Sparse and linear attention approximations reduce compute in spatial
            dimensions, but video requires temporal attention for consistency.
            We're probing whether existing sparse attention masks used for
            efficiency inadvertently disrupt cross-frame token interactions, and
            whether simple structured sparsity patterns &mdash; like attending to
            the first frame plus a local window &mdash; can recover consistency at
            lower cost. Directly relevant to autoregressive streaming pipelines
            where full temporal attention is the main bottleneck.
          </p>
          <div class="research-tags">
            <span class="tag">Sparse Attention</span>
            <span class="tag">Video Diffusion</span>
            <span class="tag">Temporal Consistency</span>
            <span class="tag">SLA</span>
            <span class="tag">SageAttention</span>
          </div>
        </div>

        <div class="research-item">
          <div class="research-item-header">
            <h3>Temporal Attention Drift in Autoregressive Video Diffusion</h3>
            <span class="status-badge active">&#9679; in progress</span>
          </div>
          <p>
            As autoregressive video models generate longer sequences, how do
            temporal attention patterns evolve? We're studying whether attention
            to early frames dilutes over time and whether this directly causes
            the quality degradation seen in long sequences. Testing whether
            forced attention anchoring to keyframes can recover consistency
            without retraining. Pure inference-time analysis &mdash; gives a
            mechanistic explanation for what Long Live and Self-Forcing++ are
            implicitly trying to fix.
          </p>
          <div class="research-tags">
            <span class="tag">AR Video</span>
            <span class="tag">Attention Drift</span>
            <span class="tag">Keyframe Anchoring</span>
            <span class="tag">Inference Analysis</span>
          </div>
        </div>


      </div>
    </section>

  </main>

  <footer>
    <div class="container">
      <p>&copy; 2026 Hudeifa Hassan</p>
      <p><a href="#">&uarr; top</a></p>
    </div>
  </footer>

</body>
</html>
